{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d370b8db-d3a4-4077-8c75-84844c1ad30b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import concurrent.futures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1d81ee1-1bab-4d1d-953c-481448e7c963",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileset = {}\n",
    "\n",
    "sig_dir = '/ceph/cms/store/user/aaportel/B-Parking/rechits_v2/BToKPhi_MuonLLPDecayGenFilter_PhiToPi0Pi0_mPhi0p3_ctau300/'\n",
    "fileset['sample'] = [sig_dir + f'BToKPhi_MuonLLPDecayGenFilter_PhiToPi0Pi0_mPhi0p3_ctau300_{str(i).zfill(7)}_graphs.pt' for i in range(328)]\n",
    "# fileset['sample'] = [sig_dir + f'BToKPhi_MuonLLPDecayGenFilter_PhiToPi0Pi0_mPhi0p3_ctau300_{str(i).zfill(7)}_graphs.pt' for i in range(100)]\n",
    "\n",
    "# bkg_dir = '/ceph/cms/store/user/aaportel/B-Parking/rechits_v2/ParkingBPH1_2018A/'\n",
    "# fileset['background'] = [bkg_dir + f'ParkingBPH1_2018A_{str(i).zfill(7)}.root' for i in range(380)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "006558ff-ca5f-4f32-b29a-38ec13c00e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, ConcatDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "\n",
    "datasets = [torch.load(fp) for fp in fileset['sample']]\n",
    "combined_dataset = ConcatDataset(datasets)\n",
    "dataloader = DataLoader(combined_dataset, batch_size=32, shuffle=True, num_workers=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b33f7d0e-b0d8-406c-9e76-79da3715967e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "\n",
    "class GNNClassifier(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_graph_features, hidden_channels):\n",
    "        super(GNNClassifier, self).__init__()\n",
    "        # GCN layers\n",
    "        self.conv1 = GCNConv(num_node_features, hidden_channels)\n",
    "        self.conv2 = GCNConv(hidden_channels, hidden_channels)\n",
    "        # Fully connected layers for graph-level features\n",
    "        self.fc_graph = Linear(num_graph_features, hidden_channels)\n",
    "        # Fully connected layers for concatenated features\n",
    "        self.fc1 = Linear(2 * hidden_channels, hidden_channels)\n",
    "        self.fc2 = Linear(hidden_channels, 1)\n",
    "\n",
    "    def forward(self, x, edge_index, batch_index, graph_features):\n",
    "        # Node feature learning\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        # Graph feature processing\n",
    "\n",
    "        graph_features = F.relu(self.fc_graph(graph_features.view(-1, num_graph_features)))\n",
    "\n",
    "        # Pooling node features to graph-level features\n",
    "        x = global_mean_pool(x, batch_index)\n",
    "\n",
    "        # Concatenate node features and graph features\n",
    "        x = torch.cat([x, graph_features], dim=1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "# Define the number of features and instantiate the model\n",
    "num_node_features = 17\n",
    "num_graph_features = 77\n",
    "hidden_channels = 64\n",
    "model = GNNClassifier(num_node_features, num_graph_features, hidden_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d77150a-4de7-484b-bc4f-75cdef9a4e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Loss = 48.8210\n",
      "Epoch 2: Loss = 48.8574\n",
      "Epoch 3: Loss = 48.8623\n",
      "Epoch 4: Loss = 48.7968\n",
      "Epoch 5: Loss = 48.8380\n",
      "Epoch 6: Loss = 48.8768\n",
      "Epoch 7: Loss = 48.8986\n",
      "Epoch 8: Loss = 48.8065\n",
      "Epoch 9: Loss = 48.8331\n",
      "Epoch 10: Loss = 48.8307\n",
      "Epoch 11: Loss = 48.8331\n",
      "Epoch 12: Loss = 48.8574\n",
      "Epoch 13: Loss = 48.7798\n",
      "Epoch 14: Loss = 48.8477\n",
      "Epoch 15: Loss = 48.8671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-1021:\n",
      "Process Process-1002:\n",
      "Process Process-1023:\n",
      "Process Process-982:\n",
      "Process Process-1019:\n",
      "Process Process-1014:\n",
      "Process Process-1016:\n",
      "Process Process-992:\n",
      "Process Process-1006:\n",
      "Process Process-995:\n",
      "Process Process-1013:\n",
      "Process Process-1012:\n",
      "Process Process-1024:\n",
      "Process Process-993:\n",
      "Process Process-1022:\n",
      "Process Process-1003:\n",
      "Process Process-1018:\n",
      "Process Process-998:\n",
      "Process Process-987:\n",
      "Process Process-1007:\n",
      "Process Process-988:\n",
      "Process Process-997:\n",
      "Process Process-991:\n",
      "Process Process-1020:\n",
      "Process Process-1005:\n",
      "Process Process-1004:\n",
      "Process Process-1010:\n",
      "Process Process-1011:\n",
      "Process Process-996:\n",
      "Process Process-1017:\n",
      "Process Process-1001:\n",
      "Process Process-1008:\n",
      "Process Process-1009:\n",
      "Process Process-1000:\n",
      "Process Process-1015:\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f3dc393ede0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/users/aaportel/mambaforge/envs/mlllp/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1478, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/users/aaportel/mambaforge/envs/mlllp/lib/python3.11/site-packages/torch/utils/data/dataloader.py\", line 1442, in _shutdown_workers\n",
      "    w.join(timeout=_utils.MP_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/users/aaportel/mambaforge/envs/mlllp/lib/python3.11/multiprocessing/process.py\", line 149, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/users/aaportel/mambaforge/envs/mlllp/lib/python3.11/multiprocessing/popen_fork.py\", line 40, in wait\n",
      "    if not wait([self.sentinel], timeout):\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/users/aaportel/mambaforge/envs/mlllp/lib/python3.11/multiprocessing/connection.py\", line 947, in wait\n",
      "    ready = selector.select(timeout)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/users/aaportel/mambaforge/envs/mlllp/lib/python3.11/selectors.py\", line 415, in select\n",
      "    fd_event_list = self._selector.poll(timeout)\n",
      "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt: \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.BCELoss()\n",
    "\n",
    "# Assuming 'dataloader' is a PyTorch Geometric DataLoader instance containing your data\n",
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        optimizer.zero_grad()  # Clear gradients.\n",
    "        data = data.to('cuda' if torch.cuda.is_available() else 'cpu')  # Move data to the device.\n",
    "        out = model(data.x, data.edge_index, data.batch, data.u)  # Forward pass.\n",
    "        loss = criterion(out.view(-1), data.y.to(torch.float))  # Compute the loss.\n",
    "        loss.backward()  # Backpropagate to compute gradients.\n",
    "        optimizer.step()  # Update model parameters.\n",
    "        total_loss += loss.item() * data.num_graphs  # Multiply by the number of graphs in the batch.\n",
    "    return total_loss / len(dataloader.dataset)  # Return the average loss.\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(100):  # Number of epochs\n",
    "    loss = train()\n",
    "    print(f'Epoch {epoch+1}: Loss = {loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "144ac16e-9c3c-4976-af56-ed898a0ca52d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "77*32"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
